{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kotsos/github/hua-thesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotsos/anaconda3/envs/gendis_test/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "/home/kotsos/anaconda3/envs/gendis_test/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/kotsos/anaconda3/envs/gendis_test/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from random import choice\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gendis.genetic import GeneticExtractor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tools.data_extraction import DataExtractor\n",
    "from tools.trajectory_generator import TrajectoryGenerator\n",
    "from tools.utils import standardize_data, print_genetic_param, print_settings, set_movements, angle_diff, get_distance\n",
    "from tools.experiments import Experiments\n",
    "\n",
    "np.random.seed(1337)  # Random seed for reproducibility\n",
    "\n",
    "tr_gen_options = {\"samples\": 25,\n",
    "                  \"freq\": 3,\n",
    "                  \"reset_data\": True}\n",
    "dt_gen_options = {\"n_test\": 150}\n",
    "\n",
    "train_test_options = {\"split\": 25}\n",
    "\n",
    "df_csv_options = {\"ts_class\": \"Bearing\"}\n",
    "\n",
    "gen_options = {\"population_size\": 20,\n",
    "               \"iterations\": 5,\n",
    "               \"verbose\": True,\n",
    "               \"normed\": True,\n",
    "               \"add_noise_prob\": 0.0,\n",
    "               \"add_shapelet_prob\": 0.3,\n",
    "               \"wait\": 10,\n",
    "               \"plot\": True,\n",
    "               \"remove_shapelet_prob\": 0.3,\n",
    "               \"crossover_prob\": 0.66,\n",
    "               \"n_jobs\": 4}\n",
    "\n",
    "settings = {\"trajectory_generator_options\": tr_gen_options,\n",
    "            \"data_generation_options\": dt_gen_options,\n",
    "            \"train_test_options\":train_test_options,\n",
    "            \"define_csvs_option\": df_csv_options,\n",
    "            \"genetic_options\": gen_options}\n",
    "\n",
    "tr_gen_options = settings[\"trajectory_generator_options\"]\n",
    "dt_gen_options = settings[\"data_generation_options\"]\n",
    "df_csvs_options = settings[\"define_csvs_option\"]\n",
    "train_test_options = settings[\"train_test_options\"]\n",
    "genetic_options = settings[\"genetic_options\"]\n",
    "\n",
    "first_movement = ['creeping_line_left']\n",
    "second_movement = ['random']\n",
    "movements = {'first_movement': first_movement,'second_movement': second_movement}\n",
    "set_movements(movements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create directory 'data' \n",
      "now creating data for movement: creeping_line_left\n",
      "now creating data for movement: random\n"
     ]
    }
   ],
   "source": [
    "# Create files if not created\n",
    "tr_gen = TrajectoryGenerator(**tr_gen_options)\n",
    "tr_gen.data_generation(**dt_gen_options)\n",
    "# Read in the datafiles\n",
    "dex = DataExtractor()\n",
    "train_df, test_df = dex.train_test_dataframes(**train_test_options)\n",
    "print(\"The train samples length is:{0}\".format(len(train_df[0] * train_test_options[\"split\"]*2)))\n",
    "print(\"The test samples length is:{0}\\n\".format(len(test_df[0] * train_test_options[\"split\"]*2)))\n",
    "dex.define_csv(**df_csvs_options)\n",
    "\n",
    "x_train, y_train, x_test, y_test = dex.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sampling(x,sampling,data_index):\n",
    "    i = 1\n",
    "    sampling_acc = True\n",
    "    down_limit = (x[1]-sampling)\n",
    "    up_limit = (x[1]+sampling)\n",
    "    while i<=sampling:\n",
    "        if 0 <=down_limit and up_limit < len(data_index):\n",
    "            if (data_index[x[1]-i] == True) or (data_index[x[1]+i] == True):\n",
    "                sampling_acc = False\n",
    "                break\n",
    "        i = i + 1      \n",
    "    return sampling_acc\n",
    "\n",
    "\n",
    "def dist_and_bearing_diff(data):\n",
    "    all_distances = []\n",
    "    bearing_diff = []\n",
    "    data_size=len(data)\n",
    "    i = 0\n",
    "    while i<data_size:\n",
    "        if i + 1 >=data_size:\n",
    "            break\n",
    "        bearing_1, bearing_2 = data[\"HEADING\"].iloc[i], data[\"HEADING\"].iloc[i+1] \n",
    "        bearing_diff.append([abs(bearing_2 - bearing_1),i])\n",
    "        lat_1, lon_1, lat_2, lon_2 = data[\"LAT\"].iloc[i], data[\"LON\"].iloc[i], data[\"LAT\"].iloc[i+1], data[\"LON\"].iloc[i+1]\n",
    "        all_distances.append(get_distance(lat_1,lon_1,lat_2,lon_2))\n",
    "        i = i +1\n",
    "    return bearing_diff, all_distances \n",
    "\n",
    "\n",
    "def fitting_indexes(arr,new_size):\n",
    "    i = 0\n",
    "    r_arr = []\n",
    "    while i <len(arr):\n",
    "        if i+1 >=len(arr):\n",
    "            break\n",
    "        r_arr.append(arr[i+1]-arr[i])\n",
    "        i = i + 1\n",
    "        \n",
    "    mean_space = mean(r_arr)\n",
    "    i = 0 \n",
    "    while i<len(arr)<new_size:\n",
    "        if i+1 >=len(arr):\n",
    "            break\n",
    "        diff = arr[i+1]-arr[i]\n",
    "        if mean_space < diff:\n",
    "            step = int(diff/2)\n",
    "            new_index = arr[i] + step\n",
    "            arr.insert(i+1,new_index)\n",
    "            i = i + 1\n",
    "        i = i + 1\n",
    "    return arr\n",
    "\n",
    "def scalling_down_windowed(data,n_sample,turn_sensitivity=35):\n",
    "    if len(data) <= n_sample :\n",
    "        return data\n",
    "    size_correction = int(len(data) / n_sample) * n_sample\n",
    "    data=data[:size_correction]\n",
    "    data_size=len(data)\n",
    "    data_index = [False for i in range(data_size)]\n",
    "    sampling = int((int(data_size/n_sample) * 0.25))\n",
    "    labels = data.columns\n",
    "    \n",
    "    temp_idx = [] \n",
    "    final_data = pd.DataFrame(data,columns=labels)\n",
    "    final_data.reset_index(drop=True)\n",
    "    \n",
    "    #find the number of bearing differance above the turn sensitivity\n",
    "    bearing_diff , all_distances = dist_and_bearing_diff(final_data)\n",
    "    mean_dist = mean(all_distances)\n",
    "    for idx, x in enumerate(bearing_diff):\n",
    "        sampling_acc = check_sampling(x,sampling,data_index)\n",
    "        if (x[0] > turn_sensitivity) and (all_distances[idx] > mean_dist/2) and sampling_acc:\n",
    "            data_index[x[1]] = True\n",
    "            temp_idx.append(x[1])\n",
    "    while n_sample > len(temp_idx):\n",
    "        final_index=fitting_indexes(temp_idx,n_sample)\n",
    "\n",
    "    for x in temp_idx:\n",
    "        data_index[x]=True\n",
    "    \n",
    "    return final_data[data_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=angle_diff(x_train)\n",
    "#x_test=angle_diff(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"TIMESTAMP\",\"LAT\",\"LON\",\"HEADING\"]\n",
    "real_data =  pd.read_csv(\"/home/kapadais/Desktop/HUA Thesis/ptixiaki hua/data/route.csv\")\n",
    "real_data = real_data [labels]\n",
    "real_data.sort_values('TIMESTAMP',inplace=True)\n",
    "real_data=real_data.reset_index(drop=True)\n",
    "data = scalling_down_windowed(real_data,train_test_options[\"split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([0,1])\n",
    "print(y_test.shape)\n",
    "a=np.array(data[\"HEADING\"].values).astype(int)\n",
    "x_test=np.array([a,x_test[1]])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the timeseries in the train and test set\n",
    "# colors = ['r', 'b', 'g', 'y', 'c']\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# for ts, label in zip(x_train, y_train):\n",
    "#     plt.plot(range(len(ts)), ts, c=colors[int(label%len(colors))])\n",
    "# plt.title('The timeseries in the train set')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# for ts, label in zip(x_test, y_test):\n",
    "#     plt.plot(range(len(ts)), ts, c=colors[int(label%len(colors))])\n",
    "# plt.title('The timeseries in the test set')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"standardized train and test data\\n\")\n",
    "x_train, x_test = standardize_data(x_train, x_test)\n",
    "genetic_extractor = GeneticExtractor(**genetic_options)\n",
    "print_genetic_param(genetic_extractor)\n",
    "genetic_extractor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_train = genetic_extractor.transform(x_train)\n",
    "distances_test = genetic_extractor.transform(x_test)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(distances_train, y_train)\n",
    "\n",
    "# Print the accuracy score on the test set\n",
    "accuracy_result = accuracy_score(y_test, lr.predict(distances_test))\n",
    "print('Accuracy = {}'.format(accuracy_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(distances_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
