{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from random import choice\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from gendis.genetic import GeneticExtractor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tools.data_extraction import DataExtractor\n",
    "from tools.trajectory_generator import TrajectoryGenerator\n",
    "from tools.utils import standardize_data, set_movements, angle_diff,scale_down\n",
    "from tools.experiments import Experiments\n",
    "\n",
    "np.random.seed(1337)  # Random seed for reproducibility\n",
    "\n",
    "tr_gen_options = {\"samples\": 25,\n",
    "                  \"freq\": 3,\n",
    "                  \"reset_data\": True}\n",
    "dt_gen_options = {\"n_test\": 200}\n",
    "\n",
    "train_test_options = {\"split\": 25}\n",
    "\n",
    "df_csv_options = {\"ts_class\": \"Bearing\"}\n",
    "\n",
    "gen_options = {\"population_size\": 25,\n",
    "               \"iterations\": 20,\n",
    "               \"verbose\": False,\n",
    "               \"normed\": True,\n",
    "               \"add_noise_prob\": 0.3,\n",
    "               \"add_shapelet_prob\": 0.3,\n",
    "               \"wait\": 10,\n",
    "               \"plot\": None,\n",
    "               \"remove_shapelet_prob\": 0.3,\n",
    "               \"crossover_prob\": 0.66,\n",
    "               \"n_jobs\": 4}\n",
    "\n",
    "settings = {\"trajectory_generator_options\": tr_gen_options,\n",
    "            \"data_generation_options\": dt_gen_options,\n",
    "            \"train_test_options\":train_test_options,\n",
    "            \"define_csvs_option\": df_csv_options,\n",
    "            \"genetic_options\": gen_options}\n",
    "\n",
    "tr_gen_options = settings[\"trajectory_generator_options\"]\n",
    "dt_gen_options = settings[\"data_generation_options\"]\n",
    "df_csvs_options = settings[\"define_csvs_option\"]\n",
    "train_test_options = settings[\"train_test_options\"]\n",
    "genetic_options = settings[\"genetic_options\"]\n",
    "\n",
    "if len(glob.glob('models')) == 0 :\n",
    "    path = \"models\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "else:\n",
    "    files = glob.glob(\"models/*\")\n",
    "    for x in files:\n",
    "        os.remove(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_list = [\"step_up_left\",\"step_up_right\",\n",
    "                 \"spiral_movement_left\",\"spiral_movement_right\",\n",
    "                 \"expanding_square_left\",\"expanding_square_right\",\n",
    "                 \"creeping_line_left\",\"creeping_line_right\",\n",
    "                 \"sector_pattern_left\",\"sector_pattern_right\"]\n",
    "all_movements = []\n",
    "for x in movement_list:\n",
    "    first_movement = [x]\n",
    "    second_movement = ['random']\n",
    "    movements = {'first_movement': first_movement,'second_movement': second_movement}\n",
    "    all_movements.append(movements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-07 01:15:47.170 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 01:15:47.174 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 01:15:47.177 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: step_up_left\n",
      "2019-06-07 01:16:03.410 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 01:16:44.362 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 01:16:44.364 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 01:16:45.359 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 01:16:46.841 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 01:16:46.879 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 01:16:46.889 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 01:16:46.891 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 01:16:46.919 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 01:37:15.670 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 01:37:15.674 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 01:37:15.677 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: step_up_right\n",
      "2019-06-07 01:37:32.253 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 01:38:13.503 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 01:38:13.505 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 01:38:14.494 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 01:38:16.162 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 01:38:16.196 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 01:38:16.207 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 01:38:16.209 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 01:38:16.233 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 01:58:10.236 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 01:58:10.238 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 01:58:10.244 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: spiral_movement_left\n",
      "2019-06-07 01:58:54.836 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 01:59:36.077 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 01:59:36.079 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 01:59:37.091 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 01:59:38.582 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 01:59:38.713 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 01:59:38.725 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 01:59:38.728 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 01:59:38.756 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 02:20:51.368 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 02:20:51.370 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 02:20:51.373 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: spiral_movement_right\n",
      "2019-06-07 02:21:36.325 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 02:22:17.444 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 02:22:17.446 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 02:22:18.430 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 02:22:19.976 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 02:22:20.021 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 02:22:20.033 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 02:22:20.041 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 02:22:20.066 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 02:43:42.339 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 02:43:42.341 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 02:43:42.345 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: expanding_square_left\n",
      "2019-06-07 02:43:46.551 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 02:44:27.997 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 02:44:27.999 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 02:44:28.967 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 02:44:30.429 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 02:44:30.558 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 02:44:30.571 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 02:44:30.573 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 02:44:30.597 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 03:00:41.358 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-07 03:00:41.360 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 03:00:41.366 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: expanding_square_right\n",
      "2019-06-07 03:00:49.601 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 03:01:30.866 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 03:01:30.868 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 03:01:31.856 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 03:01:33.336 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 03:01:33.384 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 03:01:33.394 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 03:01:33.402 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 03:01:33.427 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 03:16:12.100 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 03:16:12.103 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 03:16:12.108 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: creeping_line_left\n",
      "2019-06-07 03:16:24.450 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 03:17:05.536 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 03:17:05.538 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 03:17:06.511 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 03:17:07.962 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 03:17:07.998 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 03:17:08.009 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 03:17:08.011 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 03:17:08.039 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 03:36:27.102 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 03:36:27.106 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 03:36:27.109 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: creeping_line_right\n",
      "2019-06-07 03:36:39.233 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 03:37:20.072 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 03:37:20.073 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 03:37:21.031 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 03:37:22.474 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 03:37:22.521 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 03:37:22.533 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 03:37:22.540 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 03:37:22.566 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 03:58:08.924 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 03:58:08.926 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 03:58:08.930 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: sector_pattern_left\n",
      "2019-06-07 03:58:13.042 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 03:58:54.170 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 03:58:54.171 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 03:58:55.120 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 03:58:56.547 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 03:58:56.592 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 03:58:56.609 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 03:58:56.610 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 03:58:56.633 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-07 04:18:57.002 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-07 04:18:57.004 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-07 04:18:57.007 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: sector_pattern_right\n",
      "2019-06-07 04:19:01.181 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-07 04:19:42.627 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-07 04:19:42.629 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-07 04:19:43.590 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-07 04:19:45.004 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-07 04:19:45.052 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-07 04:19:45.069 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-07 04:19:45.070 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-07 04:19:45.092 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n"
     ]
    }
   ],
   "source": [
    "for x in all_movements:\n",
    "    set_movements(x)\n",
    "    \n",
    "    tr_gen = TrajectoryGenerator(**tr_gen_options)\n",
    "    tr_gen.data_generation(**dt_gen_options)\n",
    "    dex = DataExtractor()\n",
    "    train_df, test_df = dex.train_test_dataframes(**train_test_options)\n",
    "    dex.define_csv(**df_csvs_options)\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = dex.load_datasets()\n",
    "    x_train_anglediff=angle_diff(x_train)\n",
    "    x_test_anglediff=angle_diff(x_test)\n",
    "    \n",
    "    x_train, x_test = standardize_data(x_train, x_test)\n",
    "    x_train_anglediff, x_test_anglediff = standardize_data(x_train_anglediff, x_test_anglediff)\n",
    "    \n",
    "    genetic_extractor = GeneticExtractor(**genetic_options)\n",
    "    genetic_extractor_anglediff = GeneticExtractor(**genetic_options)\n",
    "    \n",
    "    genetic_extractor.fit(x_train, y_train)\n",
    "    genetic_extractor_anglediff.fit(x_train_anglediff,y_train)\n",
    "    \n",
    "    distances_train = genetic_extractor.transform(x_train)\n",
    "    distances_train_anglediff=genetic_extractor_anglediff.transform(x_train_anglediff)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(distances_train, y_train)\n",
    "    \n",
    "    lr_anglediff = LogisticRegression()\n",
    "    lr_anglediff.fit(distances_train_anglediff, y_train)\n",
    "    \n",
    "    mixed_distances = np.concatenate((distances_train,distances_train_anglediff),axis=1)\n",
    "    lr_mixed = LogisticRegression()\n",
    "    lr_mixed.fit(mixed_distances, y_train)\n",
    "    \n",
    "    #normal models\n",
    "    from sklearn.externals import joblib\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_logistic_regression.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(lr, pickle_file)\n",
    "        pickle_file.close()\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_genetic_extractor.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(genetic_extractor, pickle_file)\n",
    "        pickle_file.close()\n",
    "    \n",
    "    \n",
    "    #anglediff models\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_anglediff_logistic_regression.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(lr_anglediff, pickle_file)\n",
    "        pickle_file.close()\n",
    "    \n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_anglediff_genetic_extractor.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(genetic_extractor_anglediff, pickle_file)\n",
    "        pickle_file.close()\n",
    "    \n",
    "    #mixed models\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_mixed_logistic_regression.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(lr_mixed, pickle_file)\n",
    "        pickle_file.close()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
