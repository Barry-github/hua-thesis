{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from random import choice\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from gendis.genetic import GeneticExtractor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tools.data_extraction import DataExtractor\n",
    "from tools.trajectory_generator import TrajectoryGenerator\n",
    "from tools.utils import standardize_data, set_movements, angle_diff,scale_down\n",
    "from tools.experiments import Experiments\n",
    "\n",
    "np.random.seed(1337)  # Random seed for reproducibility\n",
    "\n",
    "tr_gen_options = {\"samples\": 25,\n",
    "                  \"freq\": 3,\n",
    "                  \"reset_data\": True}\n",
    "dt_gen_options = {\"n_test\": 200}\n",
    "\n",
    "train_test_options = {\"split\": 25}\n",
    "\n",
    "df_csv_options = {\"ts_class\": \"Bearing\"}\n",
    "\n",
    "gen_options = {\"population_size\": 25,\n",
    "               \"iterations\": 20,\n",
    "               \"verbose\": False,\n",
    "               \"normed\": True,\n",
    "               \"add_noise_prob\": 0.3,\n",
    "               \"add_shapelet_prob\": 0.3,\n",
    "               \"wait\": 10,\n",
    "               \"plot\": None,\n",
    "               \"remove_shapelet_prob\": 0.3,\n",
    "               \"crossover_prob\": 0.66,\n",
    "               \"n_jobs\": 4}\n",
    "\n",
    "settings = {\"trajectory_generator_options\": tr_gen_options,\n",
    "            \"data_generation_options\": dt_gen_options,\n",
    "            \"train_test_options\":train_test_options,\n",
    "            \"define_csvs_option\": df_csv_options,\n",
    "            \"genetic_options\": gen_options}\n",
    "\n",
    "tr_gen_options = settings[\"trajectory_generator_options\"]\n",
    "dt_gen_options = settings[\"data_generation_options\"]\n",
    "df_csvs_options = settings[\"define_csvs_option\"]\n",
    "train_test_options = settings[\"train_test_options\"]\n",
    "genetic_options = settings[\"genetic_options\"]\n",
    "\n",
    "if len(glob.glob('models')) == 0 :\n",
    "    path = \"models\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "else:\n",
    "    files = glob.glob(\"models/*\")\n",
    "    for x in files:\n",
    "        os.remove(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_list = [\"step_up_left\",\"step_up_right\",\n",
    "                 \"spiral_movement_right\",\"spiral_movement_left\",\n",
    "                 \"expanding_square_right\",\"expanding_square_left\",\n",
    "                 \"creeping_line_left\",\"creeping_line_right\",\n",
    "                 \"sector_pattern_left\",\"sector_pattern_right\"]\n",
    "all_movements = []\n",
    "for x in movement_list:\n",
    "    first_movement = [x]\n",
    "    second_movement = ['random']\n",
    "    movements = {'first_movement': first_movement,'second_movement': second_movement}\n",
    "    all_movements.append(movements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-04 02:21:07.040 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 02:21:07.042 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 02:21:07.044 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: step_up_left\n",
      "2019-06-04 02:21:23.566 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 02:22:04.608 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 02:22:04.610 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 02:22:05.589 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 02:22:07.054 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 02:22:07.092 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 02:22:07.106 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 02:22:07.107 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 02:22:07.131 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 02:31:10.218 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 02:31:10.243 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 02:41:23.640 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 02:41:23.642 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 02:41:23.644 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: step_up_right\n",
      "2019-06-04 02:41:40.436 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 02:42:21.855 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 02:42:21.857 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 02:42:22.852 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 02:42:24.405 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 02:42:24.450 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 02:42:24.463 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 02:42:24.464 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 02:42:24.489 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 02:49:50.814 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 02:49:50.836 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 03:02:59.694 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 03:02:59.696 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 03:02:59.698 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: spiral_movement_right\n",
      "2019-06-04 03:03:45.676 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 03:04:27.244 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 03:04:27.246 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 03:04:28.239 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 03:04:29.697 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 03:04:29.829 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 03:04:29.839 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 03:04:29.841 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 03:04:29.861 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 03:13:46.547 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 03:13:46.571 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 03:22:08.970 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 03:22:08.972 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 03:22:08.974 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: spiral_movement_left\n",
      "2019-06-04 03:22:54.796 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 03:23:36.713 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 03:23:36.716 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 03:23:37.689 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 03:23:39.269 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 03:23:39.308 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 03:23:39.320 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 03:23:39.323 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 03:23:39.349 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 03:33:42.249 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 03:33:42.273 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 03:43:26.285 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 03:43:26.287 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 03:43:26.290 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: expanding_square_right\n",
      "2019-06-04 03:43:34.692 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-04 03:44:17.047 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 03:44:17.049 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 03:44:18.028 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 03:44:19.480 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 03:44:19.519 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 03:44:19.533 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 03:44:19.534 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 03:44:19.564 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 03:56:30.764 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 03:56:30.786 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:01:57.206 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 04:01:57.208 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 04:01:57.210 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: expanding_square_left\n",
      "2019-06-04 04:02:01.503 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 04:02:43.584 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 04:02:43.586 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 04:02:44.546 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 04:02:46.163 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 04:02:46.200 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 04:02:46.211 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 04:02:46.213 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 04:02:46.234 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:12:40.017 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 04:12:40.042 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:24:17.338 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 04:24:17.340 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 04:24:17.345 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: creeping_line_left\n",
      "2019-06-04 04:24:29.578 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 04:25:11.495 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 04:25:11.498 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 04:25:12.462 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 04:25:13.875 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 04:25:13.916 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 04:25:13.930 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 04:25:13.934 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 04:25:13.960 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:35:16.529 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 04:35:16.552 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:41:52.865 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 04:41:52.868 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 04:41:52.871 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: creeping_line_right\n",
      "2019-06-04 04:42:05.277 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 04:42:46.958 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 04:42:46.960 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 04:42:47.909 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 04:42:49.323 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 04:42:49.362 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 04:42:49.375 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 04:42:49.377 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 04:42:49.401 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:50:17.701 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 04:50:17.727 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 04:57:39.194 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 04:57:39.197 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 04:57:39.202 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: sector_pattern_left\n",
      "2019-06-04 04:57:43.383 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 04:58:24.723 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 04:58:24.725 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 04:58:25.678 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 04:58:27.085 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 04:58:27.122 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 04:58:27.135 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 04:58:27.136 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-04 04:58:27.162 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 05:08:48.765 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 05:08:48.790 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 05:16:49.852 | INFO     | tools.trajectory_generator:data_generation:623 - \n",
      " Starting the generator with attributes: \n",
      "Original latitude: 37.295493\n",
      "Original longitude: 23.824322\n",
      "Initial bearing: 90\n",
      "Initial speed: 10\n",
      "Number of samples: 25\n",
      "Starting time of measurements: 2015-02-01 12:00:00\n",
      "With initial frequency of collected data: 3 min\n",
      "and hard reset of data: True\n",
      "2019-06-04 05:16:49.853 | INFO     | tools.trajectory_generator:data_generation:626 - Create directory 'generator_data' \n",
      "2019-06-04 05:16:49.857 | INFO     | tools.trajectory_generator:data_generation:632 - now creating data for movement: sector_pattern_right\n",
      "2019-06-04 05:16:54.078 | INFO     | tools.trajectory_generator:data_generation:637 - now creating data for movement: random\n",
      "2019-06-04 05:17:36.366 | SUCCESS  | tools.trajectory_generator:data_generation:670 - Done with generator\n",
      "2019-06-04 05:17:36.368 | INFO     | tools.data_extraction:read_datasets:22 - Reading the data files\n",
      "2019-06-04 05:17:37.343 | SUCCESS  | tools.data_extraction:read_datasets:51 - Done reading files\n",
      "2019-06-04 05:17:38.752 | INFO     | tools.data_extraction:define_csv:76 - Creating x_train.csv--y_train.csv and x_test.csv--y_test.csv \n",
      "2019-06-04 05:17:38.791 | SUCCESS  | tools.data_extraction:define_csv:101 - Done with train.csv\n",
      "2019-06-04 05:17:38.803 | INFO     | tools.data_extraction:define_csv:122 - Done with test.csv\n",
      "2019-06-04 05:17:38.805 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 05:17:38.829 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n",
      "2019-06-04 05:29:03.644 | INFO     | tools.data_extraction:load_datasets:129 - Loading the csv files to the appropriate train and test arrays(nparrays)\n",
      "2019-06-04 05:29:03.666 | SUCCESS  | tools.data_extraction:load_datasets:134 - Done\n"
     ]
    }
   ],
   "source": [
    "for x in all_movements:\n",
    "    set_movements(x)\n",
    "    # Create files if not created\n",
    "    tr_gen = TrajectoryGenerator(**tr_gen_options)\n",
    "    tr_gen.data_generation(**dt_gen_options)\n",
    "    # Read in the datafiles\n",
    "    dex = DataExtractor()\n",
    "    train_df, test_df = dex.train_test_dataframes(**train_test_options)\n",
    "#     print(\"The train samples length is:{0}\".format(len(train_df[0] * train_test_options[\"split\"]*2)))\n",
    "#     print(\"The test samples length is:{0}\\n\".format(len(test_df[0] * train_test_options[\"split\"]*2)))\n",
    "    dex.define_csv(**df_csvs_options)\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = dex.load_datasets()\n",
    "    x_train, x_test = standardize_data(x_train, x_test)\n",
    "    genetic_extractor = GeneticExtractor(**genetic_options)\n",
    "    genetic_extractor.fit(x_train, y_train)\n",
    "    distances_train = genetic_extractor.transform(x_train)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(distances_train, y_train)\n",
    "    from sklearn.externals import joblib\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_logistic_regression.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(lr, pickle_file)\n",
    "        pickle_file.close()\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_genetic_extractor.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(genetic_extractor, pickle_file)\n",
    "        pickle_file.close()\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = dex.load_datasets()\n",
    "    x_train=angle_diff(x_train)\n",
    "    x_test=angle_diff(x_test)\n",
    "    x_train, x_test = standardize_data(x_train, x_test)\n",
    "    genetic_extractor = GeneticExtractor(**genetic_options)\n",
    "    genetic_extractor.fit(x_train, y_train)\n",
    "    distances_train = genetic_extractor.transform(x_train)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(distances_train, y_train)\n",
    "    \n",
    "    from sklearn.externals import joblib\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_anglediff_logistic_regression.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(lr, pickle_file)\n",
    "        pickle_file.close()\n",
    "    filename = \"models/\"+x[\"first_movement\"][0]+\"_anglediff_genetic_extractor.pkl\"\n",
    "    with open(filename, 'wb') as pickle_file:\n",
    "        joblib.dump(genetic_extractor, pickle_file)\n",
    "        pickle_file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
