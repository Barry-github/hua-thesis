{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from rdp import rdp\n",
    "from statistics import mean\n",
    "from random import choice\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from gendis.genetic import GeneticExtractor\n",
    "from tools.utils import scale_down, standardize_data, set_movements, angle_diff, get_distance\n",
    "\n",
    "train_test_options = {\"split\": 25}\n",
    "movement_list = [\"step_up_left\",\"step_up_right\",\n",
    "                 \"spiral_movement_left\",\"spiral_movement_right\",\n",
    "                 \"expanding_square_left\",\"expanding_square_right\",\n",
    "                 \"creeping_line_left\",\"creeping_line_right\",\n",
    "                 \"sector_pattern_left\",\"sector_pattern_right\"]\n",
    "\n",
    "def experiments(ship,movement_list,type_exp=\"\"):\n",
    "    predictions = []\n",
    "    proba = []\n",
    "    type_exp =  \"_\"+type_exp if type_exp == \"anglediff\" else \"\"\n",
    "    for x in movement_list:\n",
    "        gen_ext = 0\n",
    "        lr = 0\n",
    "        with open(\"models/\"+x+type_exp+\"_genetic_extractor.pkl\", 'rb') as pickle_file:\n",
    "            gen_ext = joblib.load( pickle_file)\n",
    "            pickle_file.close()\n",
    "        with open(\"models/\"+x+type_exp+\"_logistic_regression.pkl\",'rb') as pickle_file:\n",
    "            lr = joblib.load(pickle_file)\n",
    "            pickle_file.close()\n",
    "        x_test = ship[\"data\"]\n",
    "        x_test = preprocessing.scale(x_test)\n",
    "        distances_test = gen_ext.transform(x_test)\n",
    "        predictions.append(lr.predict(distances_test))\n",
    "        proba.append(lr.predict_proba(distances_test))\n",
    "    return predictions,proba\n",
    "\n",
    "def results(movement_list,proba,predictions):\n",
    "    proba_info = []\n",
    "    pattern_indexes = []\n",
    "    for idx,x in enumerate(movement_list):\n",
    "        count = 0\n",
    "        indexes = []\n",
    "        for ind,i in enumerate(predictions[idx]):\n",
    "            if i ==0:\n",
    "                count = count + 1\n",
    "                proba_info.append({\"pattern\":x,\"first_class\":proba[idx][ind][0],\"second_class\":proba[idx][ind][1],\"chunk\":ind})\n",
    "                indexes.append(ind)\n",
    "#         print(count,\"times of pattern detection:\",x,\" at indexes \",indexes)\n",
    "        pattern_indexes.append(indexes)\n",
    "    return proba_info,pattern_indexes\n",
    "\n",
    "def fig_dir_creation(path,reset=False):\n",
    "    if not reset :\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except OSError:  \n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        if len(glob.glob(path))==0:\n",
    "            os.mkdir(path)\n",
    "        else:\n",
    "            shutil.rmtree(path)\n",
    "            os.mkdir(path)\n",
    "            \n",
    "def find_best_patterns(proba_info):\n",
    "    a=pd.DataFrame(proba_info,columns=[\"pattern\",\"chunk\",\"first_class\",\"second_class\"])\n",
    "    a.set_index(\"chunk\",inplace=True)\n",
    "    grouped_df = a[a.groupby(\"chunk\").count()[\"pattern\"]>1].groupby(\"chunk\")\n",
    "    best_patterns = []\n",
    "    for key, item in grouped_df:\n",
    "        temp = item[grouped_df.get_group(key).loc[key][\"first_class\"]==grouped_df.get_group(key).max()[\"first_class\"]]\n",
    "        best_patterns.append([key,temp.loc[key][\"pattern\"]])\n",
    "    for x in best_patterns:\n",
    "        print(\"For chunk no:\",x[0],\"the best pattern is \",x[1])   \n",
    "    return best_patterns\n",
    "\n",
    "def plots(movement_list,pattern_indexes,best_patterns,ship_name,ship_dfs,file=\"normal\",scaled_down=True):\n",
    "    chunks = []\n",
    "    patterns = []\n",
    "    for x in best_patterns:\n",
    "        chunks.append(x[0])\n",
    "        patterns.append(x[1])\n",
    "    for idx,x in enumerate(movement_list):\n",
    "        for ind,i in enumerate(pattern_indexes[idx]):\n",
    "            if i in chunks:\n",
    "                if(patterns[chunks.index(i)] == x):\n",
    "                    fig, ax = plt.subplots()\n",
    "                    if scaled_down:\n",
    "                        data=scale_down(ship_dfs[i],train_test_options[\"split\"]) \n",
    "                    else :\n",
    "                        data=ship_dfs[i]\n",
    "                    sns.lineplot(x='LON', y='LAT', data=data, ax=ax,sort=False,marker=\"o\")\n",
    "                    fig.set_size_inches(30, 20)\n",
    "                    ax.set_ylabel('Latitute', fontsize = 20.0) # Y label\n",
    "                    ax.set_xlabel('Longitude ', fontsize = 20.0) # X label\n",
    "                    start = datetime.strftime(ship_dfs[i][\"TIMESTAMP\"].head(1).iloc[0],'%Y-%m-%d %H:%M:%S')\n",
    "                    end = datetime.strftime(ship_dfs[i][\"TIMESTAMP\"].tail(1).iloc[0],'%Y-%m-%d %H:%M:%S')\n",
    "                    title = \"Experiment:\"+x+\"\\nCHUNK NO: \"+str(i)+\"\\n\"+start+\"----\"+end\n",
    "                    ax.set_title(title,fontsize = 20.0)\n",
    "\n",
    "            else:\n",
    "                fig, ax = plt.subplots()\n",
    "                if scaled_down:\n",
    "                        data=scale_down(ship_dfs[i],train_test_options[\"split\"]) \n",
    "                else:\n",
    "                    data=ship_dfs[i]\n",
    "                sns.lineplot(x='LON', y='LAT', data=data, ax=ax,sort=False,marker=\"o\")\n",
    "                fig.set_size_inches(30, 20)\n",
    "                ax.set_ylabel('Latitute', fontsize = 20.0) # Y label\n",
    "                ax.set_xlabel('Longitude ', fontsize = 20.0) # X label\n",
    "                start = datetime.strftime(ship_dfs[i][\"TIMESTAMP\"].head(1).iloc[0],'%Y-%m-%d %H:%M:%S')\n",
    "                end = datetime.strftime(ship_dfs[i][\"TIMESTAMP\"].tail(1).iloc[0],'%Y-%m-%d %H:%M:%S')\n",
    "                title = \"Experiment:\"+x+\"\\nCHUNK NO: \"+str(i)+\"\\n\"+start+\"----\"+end\n",
    "                ax.set_title(title,fontsize = 20.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"TIMESTAMP\",\"LAT\",\"LON\",\"HEADING\"]\n",
    "real_data =  pd.read_csv(\"../data/route.csv\")\n",
    "real_data = real_data [labels][:500]\n",
    "real_data['TIMESTAMP'] = pd.to_datetime(real_data['TIMESTAMP'])\n",
    "real_data.sort_values('TIMESTAMP',inplace=True)\n",
    "real_data=real_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First case : check for a known case of pattern (creeping_line_left for SIEM PILOT ship) if the result of code is right with the use of normal settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scale_down(real_data,train_test_options[\"split\"])\n",
    "x = np.array([x[\"HEADING\"].values.astype(int)])\n",
    "ship = {\"shipname\":\"SIEM PILOT\",\"data\":x,\"ship_dfs\":[real_data]}\n",
    "predictions,proba = experiments(ship,movement_list)\n",
    "for idx,patt in enumerate(movement_list):\n",
    "     print(\"found the pattern:\",patt,\" with probability:\",proba[idx][0][0]) if predictions[idx][0] == 0 else None\n",
    "proba_info,pattern_indexes = results(movement_list,proba,predictions)\n",
    "best_patterns = find_best_patterns(proba_info)\n",
    "plots(movement_list=movement_list,pattern_indexes=pattern_indexes,best_patterns=best_patterns,ship_name=ship[\"shipname\"],ship_dfs=ship[\"ship_dfs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second case : check for a known case of pattern (creeping_line_left for SIEM PILOT ship) if the result of code is right with the use of rdp algorithm before the scale_down section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = np.array(real_data[\"LAT\"])\n",
    "lon = np.array(real_data[\"LON\"])\n",
    "np_real_data = [np.array([x,lon[idx]]) for idx,x in enumerate(lat)]\n",
    "mask = rdp(np_real_data,algo=\"iter\", return_mask=True,epsilon=0.005)\n",
    "rdp_real_data =  real_data[mask]\n",
    "if len(rdp_real_data) == train_test_options[\"split\"]:\n",
    "    rdp_x = scale_down(rdp_real_data,train_test_options[\"split\"])\n",
    "    rdp_x = np.array([rdp_x[\"HEADING\"].values.astype(int)])\n",
    "    rdp_ship = {\"shipname\":\"SIEM PILOT\",\"data\":rdp_x,\"ship_dfs\":[rdp_real_data]}\n",
    "    rdp_predictions,rdp_proba = experiments(rdp_ship,movement_list)\n",
    "    for idx,patt in enumerate(movement_list):\n",
    "         print(\"found the pattern:\",patt,\" with probability:\",rdp_proba[idx][0][0]) if rdp_predictions[idx][0] == 0 else None\n",
    "    rdp_proba_info,rdp_pattern_indexes = results(movement_list,rdp_proba,rdp_predictions)\n",
    "    rdp_best_patterns = find_best_patterns(rdp_proba_info)\n",
    "    plots(movement_list=movement_list,pattern_indexes=rdp_pattern_indexes,best_patterns=rdp_best_patterns,ship_name=rdp_ship[\"shipname\"],ship_dfs=rdp_ship[\"ship_dfs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third case : check for a known case of pattern (creeping_line_left for SIEM PILOT ship) if the result of code is right with chunks with size 50-sample (from a trajectory with size 500-sample) using scale-down (found only 1 suitable chunk after scale down )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50  #chunk row size\n",
    "small_ship_dfs = [real_data[i:i+n] for i in range(0,real_data.shape[0],n)]\n",
    "small_ship_data_chunked = []\n",
    "small_ship_data_chunked_index = [False for i in range(0,len(small_ship_dfs))]  \n",
    "for idx,small_x in enumerate(small_ship_dfs):\n",
    "    small_x = scale_down(small_x,train_test_options[\"split\"])\n",
    "    small_x = np.array(small_x[\"HEADING\"].values.astype(int))\n",
    "    if len(small_x) == train_test_options[\"split\"]:\n",
    "        small_ship_data_chunked_index[idx] = True\n",
    "        small_ship_data_chunked.append(small_x)\n",
    "small_ship_data_chunked = np.array(small_ship_data_chunked)\n",
    "small_ship_dfs = [small_ship for (small_ship,index) in zip(small_ship_dfs,small_ship_data_chunked_index) if  index ]\n",
    "small_ship ={\"shipname\":\"SIEM PILOT\",\"data\":small_ship_data_chunked,\"ship_dfs\":small_ship_dfs}\n",
    "print(\"ERROR DIFFERENT SIZE OF DATA\") if len(small_ship_dfs)!=small_ship[\"data\"].shape[0] else None\n",
    "\n",
    "small_predictions,small_proba = experiments(small_ship,movement_list)\n",
    "for idx,patt in enumerate(movement_list):\n",
    "    print(\"found the pattern:\",patt,\" with probability:\",small_proba[idx][0][0]) if small_predictions[idx][0] == 0 else None\n",
    "small_proba_info,small_pattern_indexes = results(movement_list,small_proba,small_predictions)\n",
    "small_best_patterns = find_best_patterns(small_proba_info)\n",
    "plots(movement_list=movement_list,pattern_indexes=small_pattern_indexes,best_patterns=small_best_patterns,ship_name=small_ship[\"shipname\"],ship_dfs=small_ship[\"ship_dfs\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50-sample sized chunk plots of the  of the know SIEM PILOT's trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ship_dfs_chunk = [real_data[i:i+n] for i in range(0,real_data.shape[0],n)]\n",
    "for p_ship in small_ship_dfs_chunk:\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.lineplot(x='LON', y='LAT', data=p_ship, ax=ax,sort=False,marker=\"o\")\n",
    "    fig.set_size_inches(30, 20)\n",
    "    ax.set_ylabel('Latitute', fontsize = 20.0) # Y label\n",
    "    ax.set_xlabel('Longitude ', fontsize = 20.0) # X label\n",
    "    start = datetime.strftime(p_ship[\"TIMESTAMP\"].head(1).iloc[0],'%Y-%m-%d %H:%M:%S')\n",
    "    end = datetime.strftime(p_ship[\"TIMESTAMP\"].tail(1).iloc[0],'%Y-%m-%d %H:%M:%S')\n",
    "    title = \"Time\\n\"+start+\"----\"+end\n",
    "    ax.set_title(title,fontsize = 20.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fouth case: rerun of third case with rdp algorithm without scale down. The epsilon parameter is selected after extensive search in order to give 25-sample size trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_selection(real_data,data,size):\n",
    "    if len(real_data)<=size:\n",
    "        return False\n",
    "    else:\n",
    "        epsilon = 0\n",
    "        i = 0 \n",
    "        mask_len = len(real_data)\n",
    "        while mask_len!=size:\n",
    "#             print(\"i:\",i,mask_len,size,epsilon)\n",
    "            mask = rdp(data,algo=\"iter\", return_mask=True,epsilon=epsilon)\n",
    "            mask_len = mask.count(True)\n",
    "            if i >200:\n",
    "                return False\n",
    "            if mask_len < size:\n",
    "                if size - mask_len <=1:\n",
    "                    epsilon = epsilon - 0.0000000005\n",
    "                else :\n",
    "                    epsilon = epsilon - 0.000005\n",
    "            else:\n",
    "                if mask_len -size <=1:\n",
    "                    epsilon = epsilon + 0.00000002\n",
    "                else:\n",
    "                    epsilon = epsilon + 0.000002\n",
    "            i = i +1\n",
    "        return mask\n",
    "\n",
    "\n",
    "n = 50  #chunk row size\n",
    "small_ship_dfs = [real_data[i:i+n] for i in range(0,real_data.shape[0],n)]\n",
    "small_ship_data_chunked = []\n",
    "small_ship_data_chunked_index = [False for i in range(0,len(small_ship_dfs))]  \n",
    "\n",
    "for idx,small_x in enumerate(small_ship_dfs):\n",
    "    small_lat = np.array(small_x[\"LAT\"])\n",
    "    small_lon = np.array(small_x[\"LON\"])\n",
    "    small_np_data= [np.array([x,small_lon[idx]]) for idx,x in enumerate(small_lat)]\n",
    "    mask = epsilon_selection(small_x,small_np_data,train_test_options[\"split\"])\n",
    "    if mask:\n",
    "        small_rdp_x =  small_x[mask]\n",
    "        if len(small_rdp_x) == train_test_options[\"split\"]:\n",
    "            small_rdp_x = np.array(small_rdp_x[\"HEADING\"].values.astype(int))\n",
    "            small_ship_data_chunked_index[idx] = True\n",
    "            small_ship_data_chunked.append(small_rdp_x)\n",
    "\n",
    "\n",
    "small_ship_data_chunked = np.array(small_ship_data_chunked)\n",
    "small_ship_dfs = [small_ship for (small_ship,index) in zip(small_ship_dfs,small_ship_data_chunked_index) if  index ]\n",
    "small_rdp_ship ={\"shipname\":\"SIEM PILOT\",\"data\":small_ship_data_chunked,\"ship_dfs\":small_ship_dfs}\n",
    "print(\"ERROR DIFFERENT SIZE OF DATA\") if len(small_ship_dfs)!=small_rdp_ship[\"data\"].shape[0] else None\n",
    "\n",
    "small_rdp_predictions,small_rdp_proba = experiments(small_rdp_ship,movement_list)\n",
    "for idx,patt in enumerate(movement_list):\n",
    "    for idpred,pred in enumerate(small_rdp_predictions[idx]):\n",
    "        print(\"found the pattern:\",patt,\" with probability:\",small_rdp_proba[idx][idpred][0]) if pred== 0 else None\n",
    "small_rdp_proba_info,small_rdp_pattern_indexes = results(movement_list,small_rdp_proba,small_rdp_predictions)\n",
    "small_rdp_best_patterns = find_best_patterns(small_rdp_proba_info)\n",
    "plots(movement_list=movement_list,pattern_indexes=small_rdp_pattern_indexes,best_patterns=small_rdp_best_patterns,ship_name=small_rdp_ship[\"shipname\"],ship_dfs=small_rdp_ship[\"ship_dfs\"],scaled_down=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,patt in enumerate(movement_list):\n",
    "    for idpred,pred in enumerate(small_rdp_predictions[idx]):\n",
    "        print(\"found the pattern:\",patt,\" with probability:\",small_rdp_proba[idx][idpred][0]) if pred== 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
