{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# Pandas for managing datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from random import choice\n",
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tools.data_extraction import DataExtractor\n",
    "from tools.trajectory_generator import TrajectoryGenerator\n",
    "from tools.utils import standardize_data, print_genetic_param, print_settings, set_movements, angle_diff, get_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen_options = {\"samples\": 25,\n",
    "                  \"freq\": 5,\n",
    "                  \"reset_data\": True,\n",
    "                 \"init_speed\":20}\n",
    "dt_gen_options = {\"n_test\": 25}\n",
    "\n",
    "train_test_options = {\"split\": 25}\n",
    "\n",
    "df_csv_options = {\"ts_class\": \"Bearing\"}\n",
    "\n",
    "\n",
    "first_movement = ['creeping_line_left']\n",
    "second_movement = ['random']\n",
    "movements = {'first_movement': first_movement,'second_movement': second_movement}\n",
    "set_movements(movements)\n",
    "\n",
    "labels = [\"TIMESTAMP\",\"LAT\",\"LON\",\"HEADING\"]\n",
    "# Create files if not created\n",
    "# tr_gen = TrajectoryGenerator(**tr_gen_options)\n",
    "# tr_gen.data_generation(**dt_gen_options)\n",
    "real_data =  pd.read_csv(\"/home/kapadais/Desktop/HUA Thesis/ptixiaki hua/data/route.csv\")\n",
    "real_data = real_data [labels]\n",
    "#real_data = real_data [[\"TIMESTAMP\",\"LAT\",\"LON\"]][:750]\n",
    "real_data.sort_values('TIMESTAMP',inplace=True)\n",
    "real_data=real_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalling_down_simple(data,n_sample):\n",
    "    data_size = len(data)\n",
    "    labels = data.columns\n",
    "    sampling_offset = int(data_size/n_sample)\n",
    "    count = 0 \n",
    "    new_data = []\n",
    "    while count< data_size:\n",
    "        new_data.append(data.iloc[count])\n",
    "        count = count + sampling_offset\n",
    "    \n",
    "    return pd.DataFrame(new_data,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sampling(x,sampling,data_index):\n",
    "    i = 1\n",
    "    sampling_acc = True\n",
    "    down_limit = (x[1]-sampling)\n",
    "    up_limit = (x[1]+sampling)\n",
    "    while i<=sampling:\n",
    "        if 0 <=down_limit and up_limit < len(data_index):\n",
    "            if (data_index[x[1]-i] == True) or (data_index[x[1]+i] == True):\n",
    "                sampling_acc = False\n",
    "                break\n",
    "        i = i + 1      \n",
    "    return sampling_acc\n",
    "\n",
    "\n",
    "def dist_and_bearing_diff(data):\n",
    "    all_distances = []\n",
    "    bearing_diff = []\n",
    "    data_size=len(data)\n",
    "    i = 0\n",
    "    while i<data_size:\n",
    "        if i + 1 >=data_size:\n",
    "            break\n",
    "        bearing_1, bearing_2 = data[\"HEADING\"].iloc[i], data[\"HEADING\"].iloc[i+1] \n",
    "        bearing_diff.append([abs(bearing_2 - bearing_1),i])\n",
    "        lat_1, lon_1, lat_2, lon_2 = data[\"LAT\"].iloc[i], data[\"LON\"].iloc[i], data[\"LAT\"].iloc[i+1], data[\"LON\"].iloc[i+1]\n",
    "        all_distances.append(get_distance(lat_1,lon_1,lat_2,lon_2))\n",
    "        i = i +1\n",
    "    return bearing_diff, all_distances \n",
    "\n",
    "\n",
    "def fitting_indexes(arr,new_size):\n",
    "    i = 0\n",
    "    r_arr = []\n",
    "    while i <len(arr):\n",
    "        if i+1 >=len(arr):\n",
    "            break\n",
    "        r_arr.append(arr[i+1]-arr[i])\n",
    "        i = i + 1\n",
    "        \n",
    "    mean_space = mean(r_arr)\n",
    "    i = 0 \n",
    "    while i<len(arr)<new_size:\n",
    "        if i+1 >=len(arr):\n",
    "            break\n",
    "        diff = arr[i+1]-arr[i]\n",
    "        if mean_space < diff:\n",
    "            step = int(diff/2)\n",
    "            new_index = arr[i] + step\n",
    "            arr.insert(i+1,new_index)\n",
    "            i = i + 1\n",
    "        i = i + 1\n",
    "    return arr\n",
    "\n",
    "def scalling_down_windowed(data,n_sample,turn_sensitivity=35):\n",
    "    if len(data) <= n_sample :\n",
    "        return data\n",
    "    size_correction = int(len(data) / n_sample) * n_sample\n",
    "    data=data[:size_correction]\n",
    "    data_size=len(data)\n",
    "    data_index = [False for i in range(data_size)]\n",
    "    sampling = int((int(data_size/n_sample) * 0.25))\n",
    "    labels = data.columns\n",
    "    \n",
    "    temp_idx = [] \n",
    "    final_data = pd.DataFrame(data,columns=labels)\n",
    "    final_data.reset_index(drop=True)\n",
    "    \n",
    "    #find the number of bearing differance above the turn sensitivity\n",
    "    bearing_diff , all_distances = dist_and_bearing_diff(final_data)\n",
    "    mean_dist = mean(all_distances)\n",
    "    for idx, x in enumerate(bearing_diff):\n",
    "        sampling_acc = check_sampling(x,sampling,data_index)\n",
    "        if (x[0] > turn_sensitivity) and (all_distances[idx] > mean_dist/2) and sampling_acc:\n",
    "            data_index[x[1]] = True\n",
    "            temp_idx.append(x[1])\n",
    "    for x in temp_idx:\n",
    "    while n_sample > len(temp_idx):\n",
    "        final_index=fitting_indexes(temp_idx,n_sample)\n",
    "\n",
    "    for x in temp_idx:\n",
    "        data_index[x]=True\n",
    "    \n",
    "    return final_data[data_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = scalling_down_windowed(real_data,train_test_options[\"split\"])\n",
    "# data.reset_index(drop=True)\n",
    "# print(len(data))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30, 20)\n",
    "ax.set_ylabel('Latitute', fontsize = 20.0) # Y label\n",
    "ax.set_xlabel('Longitude ', fontsize = 20.0) # X label\n",
    "data=real_data\n",
    "#data=scalling_down_simple(data,train_test_options[\"split\"])\n",
    "data = scalling_down_windowed(real_data,train_test_options[\"split\"])\n",
    "# Plot using Seaborn\n",
    "sns.lineplot(x='LON', y='LAT', data=data, ax=ax,sort=False,marker=\"o\")\n",
    "for j, point in data.iterrows():\n",
    "    ax.text(point['LON']+0.0011, point['LAT'], str(point['HEADING']),fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
